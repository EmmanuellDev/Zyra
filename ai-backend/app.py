import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict

from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from groq import Groq
from langdetect import detect

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=getattr(logging, os.getenv('LOG_LEVEL', 'INFO')),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)

# Configure CORS
cors_origins = os.getenv('CORS_ORIGINS', '*').split(',')
CORS(app, origins=cors_origins, methods=['GET', 'POST', 'OPTIONS'], allow_headers=['Content-Type'])

# Configure Groq client
groq_client = None
if os.getenv('GROQ_API_KEY'):
    groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))

@dataclass
class AnalysisResult:
    """Data structure for AI analysis results"""
    fairness_analysis: str
    impact_analysis: str
    resource_analysis: str
    sustainability_analysis: str
    disadvantages: str
    ai_suggestion: str
    truthfulness_percentage: int
    language: str
    confidence_score: float
    timestamp: str

class AIAnalyzer:
    """AI Analysis Engine with multilingual support"""
    
    def __init__(self):
        self.supported_languages = {
            'en': 'English',
            'ta': 'Tamil',
            'kn': 'Kannada', 
            'te': 'Telugu',
           
        }
        
        self.language_prompts = {
            'en': {
                'fairness': "Analyze the fairness aspects of",
                'impact': "Evaluate the potential impact of",
                'resource': "Assess the resource requirements and utilization for",
                'sustainability': "Examine the sustainability implications of",
                'disadvantages': "Identify potential disadvantages and risks of"
            },
            'ta': {
                'fairness': "à®‡à®¤à®©à¯ à®¨à®¿à®¯à®¾à®¯à®¤à¯à®¤à®©à¯à®®à¯ˆà®¯à¯ˆ à®ªà®•à¯à®ªà¯à®ªà®¾à®¯à¯à®µà¯ à®šà¯†à®¯à¯à®¯à®µà¯à®®à¯",
                'impact': "à®‡à®¤à®©à¯ à®šà®¾à®¤à¯à®¤à®¿à®¯à®®à®¾à®© à®¤à®¾à®•à¯à®•à®¤à¯à®¤à¯ˆ à®®à®¤à®¿à®ªà¯à®ªà®¿à®Ÿà®µà¯à®®à¯",
                'resource': "à®‡à®¤à®±à¯à®•à®¾à®© à®µà®³à®¤à¯ à®¤à¯‡à®µà¯ˆà®•à®³à¯ˆ à®®à®¤à®¿à®ªà¯à®ªà®¿à®Ÿà®µà¯à®®à¯",
                'sustainability': "à®‡à®¤à®©à¯ à®¨à®¿à®²à¯ˆà®¤à¯à®¤à®©à¯à®®à¯ˆà®¯à¯ˆ à®†à®°à®¾à®¯à®µà¯à®®à¯",
                'disadvantages': "à®‡à®¤à®©à¯ à®¤à¯€à®®à¯ˆà®•à®³à¯ˆ à®…à®Ÿà¯ˆà®¯à®¾à®³à®®à¯ à®•à®¾à®£à®µà¯à®®à¯"
            },
            'kn': {
                'fairness': "à²‡à²¦à²° à²¨à³à²¯à²¾à²¯à²¸à²®à³à²®à²¤à²¤à³†à²¯à²¨à³à²¨à³ à²µà²¿à²¶à³à²²à³‡à²·à²¿à²¸à²¿",
                'impact': "à²‡à²¦à²° à²¸à²‚à²­à²¾à²µà³à²¯ à²ªà³à²°à²­à²¾à²µà²µà²¨à³à²¨à³ à²®à³Œà²²à³à²¯à²®à²¾à²ªà²¨ à²®à²¾à²¡à²¿",
                'resource': "à²‡à²¦à²•à³à²•à³† à²¬à³‡à²•à²¾à²¦ à²¸à²‚à²ªà²¨à³à²®à³‚à²²à²—à²³à²¨à³à²¨à³ à²®à³Œà²²à³à²¯à²®à²¾à²ªà²¨ à²®à²¾à²¡à²¿",
                'sustainability': "à²‡à²¦à²° à²¸à²®à²°à³à²¥à²¨à³€à²¯à²¤à³†à²¯à²¨à³à²¨à³ à²ªà²°à³€à²•à³à²·à²¿à²¸à²¿",
                'disadvantages': "à²‡à²¦à²° à²…à²¨à²¾à²¨à³à²•à³‚à²²à²¤à³†à²—à²³à²¨à³à²¨à³ à²—à³à²°à³à²¤à²¿à²¸à²¿"
            },
            'te': {
                'fairness': "à°¦à±€à°¨à°¿ à°¨à±à°¯à°¾à°¯à°®à±ˆà°¨ à°…à°‚à°¶à°¾à°²à°¨à± à°µà°¿à°¶à±à°²à±‡à°·à°¿à°‚à°šà°‚à°¡à°¿",
                'impact': "à°¦à±€à°¨à°¿ à°¸à°‚à°­à°¾à°µà±à°¯ à°ªà±à°°à°­à°¾à°µà°¾à°¨à±à°¨à°¿ à°…à°‚à°šà°¨à°¾ à°µà±‡à°¯à°‚à°¡à°¿",
                'resource': "à°¦à±€à°¨à°¿à°•à°¿ à°…à°µà°¸à°°à°®à±ˆà°¨ à°µà°¨à°°à±à°²à°¨à± à°…à°‚à°šà°¨à°¾ à°µà±‡à°¯à°‚à°¡à°¿",
                'sustainability': "à°¦à±€à°¨à°¿ à°¸à±à°¥à°¿à°°à°¤à±à°µ à°…à°‚à°¶à°¾à°²à°¨à± à°ªà°°à°¿à°¶à±€à°²à°¿à°‚à°šà°‚à°¡à°¿",
                'disadvantages': "à°¦à±€à°¨à°¿ à°ªà±à°°à°¤à°¿à°•à±‚à°² à°…à°‚à°¶à°¾à°²à°¨à± à°—à±à°°à±à°¤à°¿à°‚à°šà°‚à°¡à°¿"
            }
        }

    def detect_language(self, text: str) -> str:
        """Detect the language of the input text"""
        try:
            detected = detect(text)
            return detected if detected in self.supported_languages else 'en'
        except:
            return 'en'

    def analyze_with_groq(self, user_input: str, language: str) -> AnalysisResult:
        """Perform analysis using Groq API"""
        try:
            prompts = self.language_prompts.get(language, self.language_prompts['en'])
            
            # Create structured analysis prompts with formatting requirements
            system_prompt = f"""You are an expert analyst providing insights in {self.supported_languages[language]}. 
            IMPORTANT FORMATTING RULES:
            - Use proper markdown formatting with # for main heading
            - Use bullet points (-) for each point
            - Provide EXACTLY 2 bullet points only
            - Keep each bullet point to 1-2 lines maximum
            - Use clear, concise language
            - No long paragraphs or extensive explanations"""
            
            analysis_prompts = {
                'fairness': f"{prompts['fairness']} '{user_input}'. Format as:\n# Fairness Analysis\n- [First key fairness point in 1-2 lines]\n- [Second key fairness point in 1-2 lines]",
                'impact': f"{prompts['impact']} '{user_input}'. Format as:\n# Impact Analysis\n- [First key impact point in 1-2 lines]\n- [Second key impact point in 1-2 lines]",
                'resource': f"{prompts['resource']} '{user_input}'. Format as:\n# Resource Analysis\n- [First key resource point in 1-2 lines]\n- [Second key resource point in 1-2 lines]",
                'sustainability': f"{prompts['sustainability']} '{user_input}'. Format as:\n# Sustainability Analysis\n- [First key sustainability point in 1-2 lines]\n- [Second key sustainability point in 1-2 lines]",
                'disadvantages': f"{prompts['disadvantages']} '{user_input}'. Format as:\n# Potential Disadvantages\n- [First key disadvantage in 1-2 lines]\n- [Second key disadvantage in 1-2 lines]",
                'ai_suggestion': f"Analyze the truthfulness and provide AI suggestion for: '{user_input}'. Format as:\n# AI Suggestion\n- [Truthfulness assessment and credibility factors in 1-2 lines]\n- [Recommended actions or next steps in 1-2 lines]"
            }
            
            results = {}
            truthfulness_percentage = 50  # Default
            
            for analysis_type, prompt in analysis_prompts.items():
                if analysis_type == 'ai_suggestion':
                    # Special handling for AI suggestion with truthfulness analysis
                    truthfulness_prompt = f"""Analyze the truthfulness of this statement: '{user_input}'. 
                    Consider factors like:
                    - Consistency of information provided
                    - Presence of verifiable details  
                    - Plausibility of the scenario
                    - Potential red flags or inconsistencies
                    
                    Provide a truthfulness percentage (0-100) and brief reasoning. Format as:
                    # AI Suggestion
                    - [Brief truthfulness assessment in 1-2 lines]
                    - [Recommended next steps or actions in 1-2 lines]
                    
                    Also provide a single number (0-100) representing truthfulness percentage at the end: TRUTHFULNESS: XX"""
                    
                    response = groq_client.chat.completions.create(
                        model=os.getenv('DEFAULT_MODEL', 'llama3-8b-8192'),
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": truthfulness_prompt}
                        ],
                        temperature=float(os.getenv('TEMPERATURE', 0.3)),
                        max_tokens=int(os.getenv('MAX_TOKENS', 200))
                    )
                    content = response.choices[0].message.content.strip()
                    
                    # Extract truthfulness percentage
                    if "TRUTHFULNESS:" in content:
                        try:
                            percentage_part = content.split("TRUTHFULNESS:")[-1].strip()
                            truthfulness_percentage = int(percentage_part.split()[0])
                            # Remove the percentage line from the content
                            content = content.split("TRUTHFULNESS:")[0].strip()
                        except:
                            truthfulness_percentage = 50  # Default if parsing fails
                    
                    results[analysis_type] = content
                else:
                    response = groq_client.chat.completions.create(
                        model=os.getenv('DEFAULT_MODEL', 'llama3-8b-8192'),
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=float(os.getenv('TEMPERATURE', 0.3)),
                        max_tokens=int(os.getenv('MAX_TOKENS', 150))
                    )
                    results[analysis_type] = response.choices[0].message.content.strip()
            
            return AnalysisResult(
                fairness_analysis=results['fairness'],
                impact_analysis=results['impact'],
                resource_analysis=results['resource'],
                sustainability_analysis=results['sustainability'],
                disadvantages=results['disadvantages'],
                ai_suggestion=results['ai_suggestion'],
                truthfulness_percentage=truthfulness_percentage,
                language=language,
                confidence_score=0.9,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"Groq analysis failed: {str(e)}")
            return self.analyze_with_fallback(user_input, language)

    def analyze_with_fallback(self, user_input: str, language: str) -> AnalysisResult:
        """Fallback analysis when external APIs are not available"""
        
        # Predefined analysis templates for different topics
        analysis_templates = {
            'en': {
                'fairness': f"# Fairness Analysis\n- Equal access and unbiased treatment for all stakeholders involved\n- Transparent decision-making processes with accountability measures",
                'impact': f"# Impact Analysis\n- Positive effects include improved efficiency and innovation potential\n- Challenges may involve adaptation costs and potential disruptions",
                'resource': f"# Resource Analysis\n- Financial investment requirements and human capital needs assessment\n- Infrastructure demands with focus on cost-effectiveness and optimization",
                'sustainability': f"# Sustainability Analysis\n- Environmental responsibility with long-term viability considerations\n- Economic stability balanced with social acceptance factors",
                'disadvantages': f"# Potential Disadvantages\n- Implementation complexity and resistance to change challenges\n- Unintended consequences and resource constraint limitations",
                'ai_suggestion': f"# AI Suggestion\n- The provided information appears to have moderate credibility based on available context\n- Recommend verification through additional sources and systematic fact-checking"
            },
            'ta': {
                'fairness': f"# à®¨à®¿à®¯à®¾à®¯à®®à®¾à®© à®…à®®à¯à®šà®™à¯à®•à®³à¯ à®†à®¯à¯à®µà¯\n- à®…à®©à¯ˆà®¤à¯à®¤à¯ à®ªà®™à¯à®•à¯à®¤à®¾à®°à®°à¯à®•à®³à¯à®•à¯à®•à¯à®®à¯ à®šà®®à®®à®¾à®© à®…à®£à¯à®•à®²à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®¾à®°à®ªà®Ÿà¯à®šà®®à®±à¯à®± à®¨à®Ÿà®¤à¯à®¤à¯ˆ\n- à®µà¯†à®³à®¿à®ªà¯à®ªà®Ÿà¯ˆà®¯à®¾à®© à®®à¯à®Ÿà®¿à®µà¯†à®Ÿà¯à®•à¯à®•à¯à®®à¯ à®šà¯†à®¯à®²à¯à®®à¯à®±à¯ˆà®•à®³à¯à®Ÿà®©à¯ à®ªà¯Šà®±à¯à®ªà¯à®ªà¯à®£à®°à¯à®µà¯ à®¨à®Ÿà®µà®Ÿà®¿à®•à¯à®•à¯ˆà®•à®³à¯",
                'impact': f"# à®¤à®¾à®•à¯à®• à®†à®¯à¯à®µà¯\n- à®¨à¯‡à®°à¯à®®à®±à¯ˆà®¯à®¾à®© à®µà®¿à®³à¯ˆà®µà¯à®•à®³à®¿à®²à¯ à®®à¯‡à®®à¯à®ªà®Ÿà¯à®Ÿ à®šà¯†à®¯à®²à¯à®¤à®¿à®±à®©à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà¯à®¤à¯à®®à¯ˆ à®šà®¾à®¤à¯à®¤à®¿à®¯à®®à¯\n- à®šà®µà®¾à®²à¯à®•à®³à®¿à®²à¯ à®¤à®´à¯à®µà®²à¯ à®šà¯†à®²à®µà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®šà®¾à®¤à¯à®¤à®¿à®¯à®®à®¾à®© à®•à¯à®´à®ªà¯à®ªà®™à¯à®•à®³à¯ à®…à®Ÿà®™à¯à®•à¯à®®à¯",
                'resource': f"# à®µà®³ à®†à®¯à¯à®µà¯\n- à®¨à®¿à®¤à®¿ à®®à¯à®¤à®²à¯€à®Ÿà¯à®Ÿà¯ à®¤à¯‡à®µà¯ˆà®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®®à®©à®¿à®¤ à®®à¯‚à®²à®¤à®© à®¤à¯‡à®µà¯ˆà®•à®³à¯ à®®à®¤à®¿à®ªà¯à®ªà¯€à®Ÿà¯\n- à®šà¯†à®²à®µà¯-à®šà¯†à®¯à®²à¯à®¤à®¿à®±à®©à¯ à®®à®±à¯à®±à¯à®®à¯ à®‰à®•à®¨à¯à®¤ à®ªà®¯à®©à¯à®ªà®¾à®Ÿà¯à®Ÿà®¿à®²à¯ à®•à®µà®©à®®à¯ à®šà¯†à®²à¯à®¤à¯à®¤à¯à®®à¯ à®•à®Ÿà¯à®Ÿà®®à¯ˆà®ªà¯à®ªà¯ à®¤à¯‡à®µà¯ˆà®•à®³à¯",
                'sustainability': f"# à®¨à®¿à®²à¯ˆà®¤à¯à®¤à®©à¯à®®à¯ˆ à®†à®¯à¯à®µà¯\n- à®¨à¯€à®£à¯à®Ÿà®•à®¾à®² à®¨à®®à¯à®ªà®•à®¤à¯à®¤à®©à¯à®®à¯ˆ à®•à®°à¯à®¤à¯à®¤à¯à®•à®³à¯à®Ÿà®©à¯ à®šà¯à®±à¯à®±à¯à®šà¯à®šà¯‚à®´à®²à¯ à®ªà¯Šà®±à¯à®ªà¯à®ªà¯\n- à®šà®®à¯‚à®• à®à®±à¯à®±à¯à®•à¯à®•à¯Šà®³à¯à®³à®²à¯ à®•à®¾à®°à®£à®¿à®•à®³à¯à®Ÿà®©à¯ à®šà®®à®¨à®¿à®²à¯ˆà®¯à®¾à®© à®ªà¯Šà®°à¯à®³à®¾à®¤à®¾à®° à®¸à¯à®¤à®¿à®°à®¤à¯à®¤à®©à¯à®®à¯ˆ",
                'disadvantages': f"# à®šà®¾à®¤à¯à®¤à®¿à®¯à®®à®¾à®© à®¤à¯€à®®à¯ˆà®•à®³à¯\n- à®šà¯†à®¯à®²à¯à®ªà®Ÿà¯à®¤à¯à®¤à®²à¯ à®šà®¿à®•à¯à®•à®²à®¾à®©à®¤à¯ à®®à®±à¯à®±à¯à®®à¯ à®®à®¾à®±à¯à®±à®¤à¯à®¤à®¿à®±à¯à®•à¯ à®à®¤à®¿à®°à¯à®ªà¯à®ªà¯ à®šà®µà®¾à®²à¯à®•à®³à¯\n- à®à®¤à®¿à®°à¯à®ªà®¾à®°à®¾à®¤ à®µà®¿à®³à¯ˆà®µà¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®µà®³ à®•à®Ÿà¯à®Ÿà¯à®ªà¯à®ªà®¾à®Ÿà¯ à®µà®°à®®à¯à®ªà¯à®•à®³à¯",
                'ai_suggestion': f"# AI à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆ\n- à®µà®´à®™à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ à®¤à®•à®µà®²à¯ à®®à®¿à®¤à®®à®¾à®© à®¨à®®à¯à®ªà®•à®¤à¯à®¤à®©à¯à®®à¯ˆ à®•à¯Šà®£à¯à®Ÿà®¤à®¾à®• à®¤à¯‹à®©à¯à®±à¯à®•à®¿à®±à®¤à¯\n- à®•à¯‚à®Ÿà¯à®¤à®²à¯ à®†à®¤à®¾à®°à®™à¯à®•à®³à¯ à®®à¯‚à®²à®®à¯ à®šà®°à®¿à®ªà®¾à®°à¯à®ªà¯à®ªà¯ à®®à®±à¯à®±à¯à®®à¯ à®®à¯à®±à¯ˆà®¯à®¾à®© à®‰à®£à¯à®®à¯ˆ à®šà®°à®¿à®ªà®¾à®°à¯à®ªà¯à®ªà¯ à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆà®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®•à®¿à®±à®¤à¯"
            },
            'kn': {
                'fairness': f"# à²¨à³à²¯à²¾à²¯à²¸à²®à³à²®à²¤à²¤à³† à²µà²¿à²¶à³à²²à³‡à²·à²£à³†\n- à²à²²à³à²²à²¾ à²ªà²¾à²²à³à²¦à²¾à²°à²°à²¿à²—à³† à²¸à²®à²¾à²¨ à²ªà³à²°à²µà³‡à²¶ à²®à²¤à³à²¤à³ à²ªà²•à³à²·à²ªà²¾à²¤à²°à²¹à²¿à²¤ à²µà²°à³à²¤à²¨à³†\n- à²¹à³Šà²£à³†à²—à²¾à²°à²¿à²•à³† à²•à³à²°à²®à²—à²³à³Šà²‚à²¦à²¿à²—à³† à²ªà²¾à²°à²¦à²°à³à²¶à²• à²¨à²¿à²°à³à²§à²¾à²° à²¤à³†à²—à³†à²¦à³à²•à³Šà²³à³à²³à³à²µ à²ªà³à²°à²•à³à²°à²¿à²¯à³†à²—à²³à³",
                'impact': f"# à²ªà²°à²¿à²£à²¾à²® à²µà²¿à²¶à³à²²à³‡à²·à²£à³†\n- à²§à²¨à²¾à²¤à³à²®à²• à²ªà²°à²¿à²£à²¾à²®à²—à²³à²²à³à²²à²¿ à²¸à³à²§à²¾à²°à²¿à²¤ à²¦à²•à³à²·à²¤à³† à²®à²¤à³à²¤à³ à²¨à²¾à²µà³€à²¨à³à²¯à²¤à³† à²¸à²¾à²®à²°à³à²¥à³à²¯\n- à²¸à²µà²¾à²²à³à²—à²³à²²à³à²²à²¿ à²¹à³Šà²‚à²¦à²¾à²£à²¿à²•à³† à²µà³†à²šà³à²šà²—à²³à³ à²®à²¤à³à²¤à³ à²¸à²‚à²­à²¾à²µà³à²¯ à²…à²¡à²šà²£à³†à²—à²³à³ à²¸à³‡à²°à²¿à²°à²¬à²¹à³à²¦à³",
                'resource': f"# à²¸à²‚à²ªà²¨à³à²®à³‚à²² à²µà²¿à²¶à³à²²à³‡à²·à²£à³†\n- à²¹à²£à²•à²¾à²¸à²¿à²¨ à²¹à³‚à²¡à²¿à²•à³† à²…à²µà²¶à³à²¯à²•à²¤à³†à²—à²³à³ à²®à²¤à³à²¤à³ à²®à²¾à²¨à²µ à²¬à²‚à²¡à²µà²¾à²³ à²…à²—à²¤à³à²¯à²—à²³ à²®à³Œà²²à³à²¯à²®à²¾à²ªà²¨\n- à²µà³†à²šà³à²š-à²ªà²°à²¿à²£à²¾à²®à²•à²¾à²°à²¿à²¤à³à²µ à²®à²¤à³à²¤à³ à²…à²¨à³à²•à³‚à²²à²¤à³†à²¯ à²®à³‡à²²à³† à²—à²®à²¨ à²¹à²°à²¿à²¸à³à²µ à²®à³‚à²²à²¸à³Œà²•à²°à³à²¯ à²¬à³‡à²¡à²¿à²•à³†à²—à²³à³",
                'sustainability': f"# à²¸à²®à²°à³à²¥à²¨à³€à²¯à²¤à³† à²µà²¿à²¶à³à²²à³‡à²·à²£à³†\n- à²¦à³€à²°à³à²˜à²•à²¾à²²à³€à²¨ à²•à²¾à²°à³à²¯à²¸à²¾à²§à³à²¯à²¤à³† à²ªà²°à²¿à²—à²£à²¨à³†à²—à²³à³Šà²‚à²¦à²¿à²—à³† à²ªà²°à²¿à²¸à²° à²œà²µà²¾à²¬à³à²¦à²¾à²°à²¿\n- à²¸à²¾à²®à²¾à²œà²¿à²• à²¸à³à²µà³€à²•à²¾à²° à²…à²‚à²¶à²—à²³à³Šà²‚à²¦à²¿à²—à³† à²¸à²®à²¤à³‹à²²à²¿à²¤ à²†à²°à³à²¥à²¿à²• à²¸à³à²¥à²¿à²°à²¤à³†",
                'disadvantages': f"# à²¸à²‚à²­à²¾à²µà³à²¯ à²…à²¨à²¾à²¨à³à²•à³‚à²²à²¤à³†à²—à²³à³\n- à²…à²¨à³à²·à³à² à²¾à²¨à²¦ à²¸à²‚à²•à³€à²°à³à²£à²¤à³† à²®à²¤à³à²¤à³ à²¬à²¦à²²à²¾à²µà²£à³†à²—à³† à²ªà³à²°à²¤à²¿à²°à³‹à²§ à²¸à²µà²¾à²²à³à²—à²³à³\n- à²…à²¨à²ªà³‡à²•à³à²·à²¿à²¤ à²ªà²°à²¿à²£à²¾à²®à²—à²³à³ à²®à²¤à³à²¤à³ à²¸à²‚à²ªà²¨à³à²®à³‚à²² à²¨à²¿à²°à³à²¬à²‚à²§ à²®à²¿à²¤à²¿à²—à²³à³",
                'ai_suggestion': f"# AI à²¸à²²à²¹à³†\n- à²’à²¦à²—à²¿à²¸à²¿à²¦ à²®à²¾à²¹à²¿à²¤à²¿à²¯à³ à²®à²§à³à²¯à²® à²µà²¿à²¶à³à²µà²¾à²¸à²¾à²°à³à²¹à²¤à³†à²¯à²¨à³à²¨à³ à²¹à³Šà²‚à²¦à²¿à²°à³à²µà²‚à²¤à³† à²•à²‚à²¡à³à²¬à²°à³à²¤à³à²¤à²¦à³†\n- à²¹à³†à²šà³à²šà³à²µà²°à²¿ à²®à³‚à²²à²—à²³ à²®à³‚à²²à²• à²ªà²°à²¿à²¶à³€à²²à²¨à³† à²®à²¤à³à²¤à³ à²µà³à²¯à²µà²¸à³à²¥à²¿à²¤ à²¸à²¤à³à²¯ à²ªà²°à³€à²•à³à²·à³†à²¯à²¨à³à²¨à³ à²¶à²¿à²«à²¾à²°à²¸à³ à²®à²¾à²¡à²²à²¾à²—à³à²¤à³à²¤à²¦à³†"
            },
            'te': {
                'fairness': f"# à°¨à±à°¯à°¾à°¯à°®à±ˆà°¨ à°…à°‚à°¶à°¾à°² à°µà°¿à°¶à±à°²à±‡à°·à°£\n- à°…à°¨à±à°¨à°¿ à°µà°¾à°Ÿà°¾à°¦à°¾à°°à±à°²à°•à± à°¸à°®à°¾à°¨ à°ªà±à°°à°µà±‡à°¶à°‚ à°®à°°à°¿à°¯à± à°ªà°•à±à°·à°ªà°¾à°¤à°‚ à°²à±‡à°¨à°¿ à°µà±à°¯à°µà°¹à°¾à°°à°‚\n- à°œà°µà°¾à°¬à±à°¦à°¾à°°à±€à°¤à°¨à°‚ à°šà°°à±à°¯à°²à°¤à±‹ à°ªà°¾à°°à°¦à°°à±à°¶à°• à°¨à°¿à°°à±à°£à°¯à°¾à°§à°¿à°• à°ªà±à°°à°•à±à°°à°¿à°¯à°²à±",
                'impact': f"# à°ªà±à°°à°­à°¾à°µ à°µà°¿à°¶à±à°²à±‡à°·à°£\n- à°¸à°¾à°¨à±à°•à±‚à°² à°ªà±à°°à°­à°¾à°µà°¾à°²à°²à±‹ à°®à±†à°°à±à°—à±ˆà°¨ à°¸à°¾à°®à°°à±à°¥à±à°¯à°‚ à°®à°°à°¿à°¯à± à°†à°µà°¿à°·à±à°•à°°à°£ à°¸à°‚à°­à°¾à°µà±à°¯à°¤\n- à°¸à°µà°¾à°³à±à°²à°²à±‹ à°…à°¨à±à°¸à°°à°£ à°–à°°à±à°šà±à°²à± à°®à°°à°¿à°¯à± à°¸à°‚à°­à°¾à°µà±à°¯ à°…à°‚à°¤à°°à°¾à°¯à°¾à°²à± à°‰à°‚à°¡à°µà°šà±à°šà±",
                'resource': f"# à°µà°¨à°°à±à°² à°µà°¿à°¶à±à°²à±‡à°·à°£\n- à°†à°°à±à°¥à°¿à°• à°ªà±†à°Ÿà±à°Ÿà±à°¬à°¡à°¿ à°…à°µà°¸à°°à°¾à°²à± à°®à°°à°¿à°¯à± à°®à°¾à°¨à°µ à°®à±‚à°²à°§à°¨ à°…à°µà°¸à°°à°¾à°² à°…à°‚à°šà°¨à°¾\n- à°µà±à°¯à°¯-à°ªà±à°°à°­à°¾à°µà°‚ à°®à°°à°¿à°¯à± à°…à°¨à±à°•à±‚à°²à±€à°•à°°à°£à°ªà±ˆ à°¦à±ƒà°·à±à°Ÿà°¿ à°ªà±†à°Ÿà±à°Ÿà±‡ à°®à±Œà°²à°¿à°• à°¸à°¦à±à°ªà°¾à°¯à°¾à°² à°¡à°¿à°®à°¾à°‚à°¡à±à°²à±",
                'sustainability': f"# à°¸à±à°¥à°¿à°°à°¤à±à°µ à°µà°¿à°¶à±à°²à±‡à°·à°£\n- à°¦à±€à°°à±à°˜à°•à°¾à°²à°¿à°• à°®à°¨à±à°—à°¡ à°ªà°°à°¿à°—à°£à°¨à°²à°¤à±‹ à°ªà°°à±à°¯à°¾à°µà°°à°£ à°¬à°¾à°§à±à°¯à°¤\n- à°¸à°¾à°®à°¾à°œà°¿à°• à°†à°®à±‹à°¦à°‚ à°•à°¾à°°à°•à°¾à°²à°¤à±‹ à°¸à°®à°¤à±à°²à±à°¯ à°†à°°à±à°¥à°¿à°• à°¸à±à°¥à°¿à°°à°¤à±à°µà°‚",
                'disadvantages': f"# à°¸à°‚à°­à°¾à°µà±à°¯ à°ªà±à°°à°¤à°¿à°•à±‚à°²à°¤à°²à±\n- à°…à°®à°²à± à°¸à°‚à°•à±à°²à°¿à°·à±à°Ÿà°¤ à°®à°°à°¿à°¯à± à°®à°¾à°°à±à°ªà±à°•à± à°ªà±à°°à°¤à°¿à°˜à°Ÿà°¨ à°¸à°µà°¾à°³à±à°²à±\n- à°…à°¨à°¾à°²à±‹à°šà°¿à°¤ à°ªà°°à°¿à°£à°¾à°®à°¾à°²à± à°®à°°à°¿à°¯à± à°µà°¨à°°à±à°² à°ªà°°à°¿à°®à°¿à°¤à°¿ à°ªà°°à°¿à°®à°¿à°¤à±à°²à±",
                'ai_suggestion': f"# AI à°¸à±‚à°šà°¨\n- à°…à°‚à°¦à°¿à°‚à°šà°¿à°¨ à°¸à°®à°¾à°šà°¾à°°à°‚ à°®à°§à±à°¯à°¸à±à°¥ à°µà°¿à°¶à±à°µà°¸à°¨à±€à°¯à°¤ à°•à°²à°¿à°—à°¿ à°‰à°¨à±à°¨à°Ÿà±à°²à± à°•à°¨à°¿à°ªà°¿à°¸à±à°¤à±à°‚à°¦à°¿\n- à°…à°¦à°¨à°ªà± à°®à±‚à°²à°¾à°² à°¦à±à°µà°¾à°°à°¾ à°§à±à°°à±à°µà±€à°•à°°à°£ à°®à°°à°¿à°¯à± à°µà±à°¯à°µà°¸à±à°¥à°¾à°ªà°¿à°¤ à°µà°¾à°¸à±à°¤à°µ à°¤à°¨à°¿à°–à±€à°¨à°¿ à°¸à°¿à°«à°¾à°°à±à°¸à± à°šà±‡à°¸à±à°¤à±à°¨à±à°¨à°¾à°®à±"
            }
        }
        
        lang_templates = analysis_templates.get(language, analysis_templates['en'])
        
        return AnalysisResult(
            fairness_analysis=lang_templates['fairness'],
            impact_analysis=lang_templates['impact'],
            resource_analysis=lang_templates['resource'],
            sustainability_analysis=lang_templates['sustainability'],
            disadvantages=lang_templates['disadvantages'],
            ai_suggestion=lang_templates['ai_suggestion'],
            truthfulness_percentage=75,  # Default percentage for fallback
            language=language,
            confidence_score=0.8,
            timestamp=datetime.now().isoformat()
        )

    def analyze(self, user_input: str, preferred_language: Optional[str] = None) -> AnalysisResult:
        """Main analysis method"""
        # Detect or use preferred language
        if preferred_language and preferred_language in self.supported_languages:
            language = preferred_language
        else:
            language = self.detect_language(user_input)
        
        logger.info(f"Analyzing input in {language}: {user_input[:50]}...")
        
        # Try Groq first, fallback to template-based analysis
        if os.getenv('GROQ_API_KEY') and groq_client:
            try:
                return self.analyze_with_groq(user_input, language)
            except Exception as e:
                logger.warning(f"Groq analysis failed, using fallback: {str(e)}")
                return self.analyze_with_fallback(user_input, language)
        else:
            logger.info("Using fallback analysis (no Groq API key)")
            return self.analyze_with_fallback(user_input, language)

# Initialize analyzer
analyzer = AIAnalyzer()

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'supported_languages': list(analyzer.supported_languages.keys())
    })

@app.route('/analyze', methods=['POST'])
def analyze_text():
    """Main analysis endpoint"""
    try:
        data = request.get_json()
        
        if not data or 'message' not in data:
            return jsonify({'error': 'Message is required'}), 400
        
        user_input = data['message'].strip()
        preferred_language = data.get('language', None)
        
        if not user_input:
            return jsonify({'error': 'Message cannot be empty'}), 400
        
        # Perform analysis
        result = analyzer.analyze(user_input, preferred_language)
        
        # Convert to dict for JSON response
        response_data = asdict(result)
        
        logger.info(f"Analysis completed for language: {result.language}")
        
        return jsonify({
            'success': True,
            'analysis': response_data
        })
        
    except Exception as e:
        logger.error(f"Analysis error: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'Internal server error occurred'
        }), 500

@app.route('/languages', methods=['GET'])
def get_supported_languages():
    """Get list of supported languages"""
    return jsonify({
        'supported_languages': analyzer.supported_languages
    })

@app.route('/chat', methods=['POST'])
def chat_endpoint():
    """Simple chat endpoint for basic conversations"""
    try:
        data = request.get_json()
        
        if not data or 'message' not in data:
            return jsonify({'error': 'Message is required'}), 400
        
        user_input = data['message'].strip()
        language = data.get('language', 'en')
        
        if not user_input:
            return jsonify({'error': 'Message cannot be empty'}), 400
        
        # For simple chat, provide a basic response
        if user_input.lower() in ['hello', 'hi', 'hey', 'à®µà®£à®•à¯à®•à®®à¯', 'à²¨à²®à²¸à³à²•à²¾à²°', 'à°¨à°®à°¸à±à°•à°¾à°°à°‚']:
            responses = {
                'en': "Hello! I'm an AI assistant that can analyze various aspects of your questions including fairness, impact, resources, sustainability, and potential disadvantages. How can I help you today?",
                'ta': "à®µà®£à®•à¯à®•à®®à¯! à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à®¿à®©à¯ à®¨à®¿à®¯à®¾à®¯à®¤à¯à®¤à®©à¯à®®à¯ˆ, à®¤à®¾à®•à¯à®•à®®à¯, à®µà®³à®™à¯à®•à®³à¯, à®¨à®¿à®²à¯ˆà®¤à¯à®¤à®©à¯à®®à¯ˆ à®®à®±à¯à®±à¯à®®à¯ à®šà®¾à®¤à¯à®¤à®¿à®¯à®®à®¾à®© à®¤à¯€à®®à¯ˆà®•à®³à¯ à®‰à®Ÿà¯à®ªà®Ÿ à®ªà®²à¯à®µà¯‡à®±à¯ à®…à®®à¯à®šà®™à¯à®•à®³à¯ˆ à®ªà®•à¯à®ªà¯à®ªà®¾à®¯à¯à®µà¯ à®šà¯†à®¯à¯à®¯à®•à¯à®•à¯‚à®Ÿà®¿à®¯ AI à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯. à®‡à®©à¯à®±à¯ à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®à®ªà¯à®ªà®Ÿà®¿ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯?",
                'kn': "à²¨à²®à²¸à³à²•à²¾à²°! à²¨à²¾à²¨à³ à²¨à³à²¯à²¾à²¯à²¸à²®à³à²®à²¤à²¤à³†, à²ªà²°à²¿à²£à²¾à²®, à²¸à²‚à²ªà²¨à³à²®à³‚à²²à²—à²³à³, à²¸à²®à²°à³à²¥à²¨à³€à²¯à²¤à³† à²®à²¤à³à²¤à³ à²¸à²‚à²­à²¾à²µà³à²¯ à²…à²¨à²¾à²¨à³à²•à³‚à²²à²¤à³†à²—à²³à³ à²¸à³‡à²°à²¿à²¦à²‚à²¤à³† à²¨à²¿à²®à³à²® à²ªà³à²°à²¶à³à²¨à³†à²—à²³ à²µà²¿à²µà²¿à²§ à²…à²‚à²¶à²—à²³à²¨à³à²¨à³ à²µà²¿à²¶à³à²²à³‡à²·à²¿à²¸à²¬à²²à³à²² AI à²¸à²¹à²¾à²¯à²•. à²‡à²‚à²¦à³ à²¨à²¾à²¨à³ à²¨à²¿à²®à²—à³† à²¹à³‡à²—à³† à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²¹à³à²¦à³?",
                'te': "à°¨à°®à°¸à±à°•à°¾à°°à°‚! à°¨à±‡à°¨à± à°¨à±à°¯à°¾à°¯à°®à±ˆà°¨ à°…à°‚à°¶à°¾à°²à±, à°ªà±à°°à°­à°¾à°µà°‚, à°µà°¨à°°à±à°²à±, à°¸à±à°¥à°¿à°°à°¤à±à°µà°‚ à°®à°°à°¿à°¯à± à°¸à°‚à°­à°¾à°µà±à°¯ à°ªà±à°°à°¤à°¿à°•à±‚à°²à°¤à°²à°¤à±‹ à°¸à°¹à°¾ à°®à±€ à°ªà±à°°à°¶à±à°¨à°² à°¯à±Šà°•à±à°• à°µà°¿à°µà°¿à°§ à°…à°‚à°¶à°¾à°²à°¨à± à°µà°¿à°¶à±à°²à±‡à°·à°¿à°‚à°šà°—à°² AI à°¸à°¹à°¾à°¯à°•à±à°¡à°¨à±. à°ˆà°°à±‹à°œà± à°¨à±‡à°¨à± à°®à±€à°•à± à°à°²à°¾ à°¸à°¹à°¾à°¯à°ªà°¡à°—à°²à°¨à±?"
            }
            
            return jsonify({
                'success': True,
                'response': responses.get(language, responses['en']),
                'language': language
            })
        
        # For other messages, perform full analysis
        result = analyzer.analyze(user_input, language)
        
        # Format as a conversational response
        response_text = f"""Based on your message about "{user_input}", here's my comprehensive analysis:

ğŸ” **Fairness Analysis**: {result.fairness_analysis}

ğŸ“Š **Impact Analysis**: {result.impact_analysis}

ğŸ’° **Resource Analysis**: {result.resource_analysis}

ğŸŒ± **Sustainability Analysis**: {result.sustainability_analysis}

âš ï¸ **Potential Disadvantages**: {result.disadvantages}

ğŸ¤– **AI Suggestion**: {result.ai_suggestion}

ğŸ“ˆ **Truthfulness Assessment**: {result.truthfulness_percentage}% credibility based on available information

Would you like me to elaborate on any specific aspect?"""
        
        return jsonify({
            'success': True,
            'response': response_text,
            'detailed_analysis': asdict(result),
            'language': result.language
        })
        
    except Exception as e:
        logger.error(f"Chat error: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'Internal server error occurred'
        }), 500

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    host = os.getenv('HOST', '0.0.0.0')
    debug = os.getenv('DEBUG', 'True').lower() == 'true'
    
    logger.info(f"Starting AI Analysis Server on {host}:{port}")
    logger.info(f"Supported languages: {list(analyzer.supported_languages.keys())}")
    logger.info(f"Groq API configured: {'Yes' if groq_client else 'No (using fallback analysis)'}")
    
    app.run(host=host, port=port, debug=debug)